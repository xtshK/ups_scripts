import requests
from requests.auth import HTTPBasicAuth
import pandas as pd
from io import StringIO
import os
from datetime import datetime

# UPS åˆ—è¡¨è¨­å®šï¼ˆå«æ¨“å±¤/IP/typeï¼‰
ups_targets = [
    {"name": "UPS_3F", "ip": "172.21.5.14", "type": "standard"},
    {"name": "UPS_7F", "ip": "172.21.6.10", "type": "standard"},
    {"name": "UPS_8F", "ip": "172.21.4.10", "type": "standard"},
    {"name": "UPS_9F", "ip": "172.21.3.11", "type": "standard"},
    {"name": "UPS_10F", "ip": "172.21.2.13", "type": "new"}  # ç‰¹åˆ¥è™•ç†
]

username = "admin"
password = "misadmin"
output_dir = "ups_logs"

onelake_path = r"C:\Users\kuose\OneLake - Microsoft\global-IT-DEV\selena_lakehouse.Lakehouse\Files"
output_dir = os.path.join(onelake_path, "ups_data_all")
os.makedirs(output_dir, exist_ok=True)

target_date = datetime.today().strftime("%Y%m%d")

for ups in ups_targets:
    ups_name = ups["name"]
    ip = ups["ip"]
    ups_type = ups["type"]
    print(f"ğŸ“¡ æ­£åœ¨ä¸‹è¼‰ {ups_name} çš„è³‡æ–™...")

    if ups_type == "standard":
        session = requests.Session()
        session.get(f"http://{ip}", auth=HTTPBasicAuth(username, password))     
        url = f"http://{ip}/cgi-bin/datalog.csv?page=421&"
        form_data = {"GETDATFILE": "Download"}
    else:
        session = requests.Session()
        session.auth = HTTPBasicAuth(username, password)
        session.get(f"http://{ip}/refresh_data.cgi", params="data_date=" + target_date)
        url = f"http://{ip}/download.cgi"
        form_data = {"data_date": target_date}

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": f"http://{ip}"
    }

    response = session.post(url, headers=headers, data=form_data, auth=HTTPBasicAuth(username, password))

    if response.status_code == 200 and len(response.content) > 100:
        try:
            decoded = response.content.decode("utf-8", errors="ignore")
            df = pd.read_csv(StringIO(decoded), header=None, skiprows=1)

            # æ¬„ä½æ¨™æº–åŒ–
            if ups_type == "standard":
                df.columns = ["Date", "Time", "Vin", "Vout", "Vbat", "Fin", "Fout", "Load", "Temp"]
                df["UPS_Name"] = ups_name
                df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.strftime("%Y-%m-%d")
            else:
                df.columns = ["DateTime", "Vin", "Vout", "Freq", "Load", "Capacity", "Vbat", "CellVolt", "Temp"]
                df = df.dropna(subset=["DateTime"])
                df[["Date", "Time"]] = df["DateTime"].str.strip().str.split(" ", expand=True, n=1)
                df.drop(columns=["DateTime", "Capacity", "CellVolt"], inplace=True)
                df["Fin"] = df["Freq"]
                df["Fout"] = df["Freq"]
                df["Temp"] = df["Temp"].str.extract(r"([\d\.]+)").astype(float)
                df = df[["Date", "Time", "Vin", "Vout", "Vbat", "Fin", "Fout", "Load", "Temp"]]
                df["UPS_Name"] = ups_name
                df["Date"] = pd.to_datetime(df["Date"], errors="coerce").dt.strftime("%Y-%m-%d")

            # â¬‡ï¸ å„²å­˜ç‚º combined æª”æ¡ˆï¼ˆé˜²é‡è¤‡ï¼‰
            combined_path = f"{output_dir}/{ups_name}.csv"
            if os.path.exists(combined_path):
                # å¦‚æœå·²å­˜åœ¨ï¼Œè®€å–ä¸¦åˆä½µ
                existing = pd.read_csv(combined_path)
                combined = pd.concat([existing, df], ignore_index=True)
                combined.drop_duplicates(subset=["Date", "Time", "UPS_Name"], inplace=True)
            else:
                # å¦‚æœä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ç•¶å‰ DataFrame
                combined = df

            combined.to_csv(combined_path, index=False)
            print(f"âœ… {ups_name} å¯«å…¥ {combined_path}ï¼Œç¸½ç­†æ•¸ï¼š{len(combined)}")

        except Exception as e:
            print(f"âš ï¸  è½‰æ›å¤±æ•—ï¼š{e}")
    else:
        print(f"âŒ {ups_name} ä¸‹è¼‰å¤±æ•—ï¼šç‹€æ…‹ç¢¼ {response.status_code}")
# 